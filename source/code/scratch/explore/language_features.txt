Various language features and code generation ideas to support:

- Option to make function result cached
this could turn a regular function into a function that holds the result as a static.
It may also create an additional function so that there is a cached / noncached version.

- Tag portions of unilang structure as "generated" or "not generated".
Based on options an code generation, we are going to be changing the actual unilang structure pragmatically.
adding methods to the methods section. Adding data members to objects. All kinds of things.
All of this data needs an enum for SPECIFIED/GENERATED. in accordance to what is contained in the actual .UniLang file.
We may also accomplish this at the graphical level with an additional label face that holds this property.

- Side Effects
The language may be purely functional, it may not be.
If side effects are a possibility we should consider having a token that says what the side effects are?
At least an English comment about the side effect.
And as far as I understand contract programming, side effects are not post conditions.
If the function does not complete successfully, the post conditions are irrelevant.
Side effects aren't necessarily exceptions either. That's why I think a separate language tokens may be needed.
Hopefully this something we can detect and generate automatically. Might need a token for this, but I'm hoping that we don't.
// side effects:
// - uses IO
// - changes global var: foo

- Higher Order Detector
We need a function that takes a look at all the arguments and return values,
and decides whether it is a higher order function. Not too hard.
We need to backtrack and find function pointers. Looks at std::function.
I guess some classes could have () overloaded..
does that mean the function is actually higher order. More to consider here.

- Idempotence Detector
A function is idempotent if reapplying it to its result does not produce a different result.
Not sure how difficult this come to be.
Might have to implement other features first-- like detecting side effects, etc.
Although having side effects doesn't mean the function isn't still idempotent.
So than there is a whole flow analysis involved. Tricky.

- [why change value] token for data members
Often times a chunk of data is sent into some business logic.
The data has a brief/detailed description,
but sometimes it is useful to describe WHY a user may want to change the data.
The can also serve as additional GUI text in say a settings panel.

- [questionable] token to code elements
sometimes you have to make a change to some code.
Those changes may be hackish, and somewhat questionable.
Other times, you are implementing something off of a requirement specification, and you don't agree with the requirement specification.
Maybe the requirement specification is wrong, but you don't have time to hold off on implementation until you know.
I think the best thing to so in these situations, is tag a particular code element as "questionable".
That way it is self documenting (better than just a regular comment).
The "questionable" will just be a string explaining why you find the code element questionable.
If it doesn't exist, then the code is not questionable. Easy to implement, lots of tokens though for every code element.
I assume this is going to be similar to the "deprecation" or "warning" or "note" attributes.

- [optional why] token
we'll be able to tag arguments, return values, identifiers as "optional".
We will also be able to supply a list of reasons as to why the variable may be optional.

- [reason] token
pretty much every token should have a corresponding "reason" tokens
why did you choose this type?
why did you choose this default value?
why did you choose these units?
etc...

- [error message] token values
[what happened]
[why]
[suggest next step]
[rate the seriousness of the issue]
^ this can guide static analysis in deciding whether the error message has the right tone.

- [context] token
types should come with a context type; this auto populate documentation where used
types should come with a table of "context" / description
then when you use arguments, you use them with a context.
The context can automatically populate the argument description.
void function([string][storing]){}
void function([string][printing]){}
the context is defined alongside the type deceleration/definition.
This also allows people to take a type and understand the contexts in which its used.

[problem] & [solution] token
we need to add a problem and solution tag to the language.
We can verify that it exists, warn if it doesn't and print it as part of documentation

[improvements] token
tokens to show general TODOs and improvements to be made to the code.
That way when a new diff comes up, it shows the deletion of the comment also.

- TODO(message) CONSIDER(message) WORRY(message) CONFUSED(message)
We need another specific comment tags.
Like TODO, but these ones give additional context on what we are trying to convey

- Mustache settings for different parts of the unilang structure
we'll have to think about how wildly this can be used, and if it should be ignored by just using language features instead

- time tracking, and file navigation recording
this stupid but it would be cool if we recorded (somehow), how long a programmer has been looking at file.
If they aren't scrolling or moving their mouse or something, we'll have some kind of timeout.
The idea is, that we will be able to show hot spots where people spend their time looking a lot.
And see cold spots where people pretty much trust, or have no need to look at certain code.
It would also be cool to record the file tracing that occurs for programmers.
For example, they might look at a child class, and then most would look at some parent class,
and then maybe they would go to class thats composed inside the parent.
We can trace these file jumps to determine if users are jumping to disconnected files for particular reasons.
This can help determine cohesion and such.
Also, allow microphone listening, to learn about a particular file.
based on people cursing, and cursing other people's names etc.
AI can learn about a programmer's feelings toward a particular file.

- generate or not generate auto based on specified conditions
converting between using auto and not using auto should be an algorithmic conversion.
this is mostly a c++ concern both other languages that have similar auto concept as well.
even java with choosing Object even thought this is different than type deduction

- provide a way to duplicate const on methods
example for c++:
class some_class{
    ...
    const std::map<std::string, std::string> &get_value_items() const;
    std::map<std::string, std::string> &      get_value_items();
   ...
 };
 
 - static analysis refactor suggestions
o detecting patterns and recommending templates
o detecting patterns and recommending higher order functions
o o help data bubble to the top
find duplicate code and suggest function interface
I think there is a lot of re-factoring opportunities that lead you down different roads when re-factoring.
Sometimes it pays off, sometimes it does not. We need to do some research on what re-factoring techniques work, and which do not.
I'd like to set up an experiment with made up types, and made up functionalists, and try different scenarios and use-cases to see how decisions pan out.
Maybe there is some research papers on the matter that we can tap into

- generate "to_tuple" free function / member function
all types should be able to generate to tuples.
Keep in mind, that we might want the order of the tuple arguments based on size to create the best alignment.
We may also want them in the order that they were originally in the class.

- all functions should be tagged with their "category of transform"
every function is some kind of transform.
We should be able to categorize these transforms.
A function can belong to more than one group.
Examples:
 converters
 accumulators
 transformers
 sorters
 printers (return nothing. has side effects)
 -validators (return bool)
 describers (takes a structure and describes it with another type. I dunno. something like that)
 builders
-generators
We'll want to come up with clear definitions for all of these.
Hopefully we can add enough semantics to detect a function's "category of transformation"
automatically. Also, some "transform" categories inherit. For example,
if you call a printer internally, you are also a printer. Not so much if you call coverters/transformers etc.
You would be a printer even if the function doesn't actually print if its blocked by a conditional or something which we wouldn't be able to figure out.


- homoglyph substitution and zero-width fingerprinting
It would be super sneaky and super sly to watermark generated code with unilang zero-width fingerprinting.
This way we'll now if someone has copied code, etc.

- allow inserting zero width character messages
similar to:
https://umpox.github.io/zero-width-detection/
https://medium.com/@umpox/be-careful-what-you-copy-invisibly-inserting-usernames-into-text-with-zero-width-characters-18b4e6f17b66
(for secret watermarks)

- measuring technical debt
this is stupid but lets say technical debt exists from an "interest rate"
and "interest rate" is a function of time. Let's see if we can get a rough algorithm to compute and keep track of this on functions/classes/modules

- demonstrative detector
"Instead of using demonstratives “this” and “that” or pronouns like “it” or “they“, use the specific names of the things, even if it seems slightly redundant.
It’s especially good for the case when you are focused on technical writing which often requires referring to many different things at once, which may confuse the reader."

- comments that use terms must link to definition
static analysis of comment. We find acronyms, concepts, and terms. These must be linked to the name that has all of the necessary contextual information.

- code should have music associated with it
music can also inspire feelings about a particular piece of code, and can help someone gain familiarity

- warn about proposition-looking functions that have out prams
if the function name looks like its asking a question, i.e.
by analyzing the semantics/pragmatics of the function name and that it returns a bool, it is most likely a proposition of sorts.
(Note: Unilang might have a way of directly specifying this proposition, in which case it will be literally just checking more of a property of the function).
Wither way, if we have some kind of proposition, it would make sense for functions to not have out params.
We can statically warn about this,.
The reason this ticket exists is because I've been bitted by this while trying to unit test something and not understanding why I was getting different results when reusing the same arguments.

- some functions are questions (allow unilang to detect this) 
some functions return a bool, which means they are asking a question.
We may want documentation tools to specify what that question means.
Some bool return functions only observe and return true/false
Others try to do something and return true/false for whether it succeeds.
So for example:
bool WriteToFile(string text, File & file);
We want to generate documentation that says:
"Did writing to the file succeed?"
Other stuff to look into such as EitherType.
Thinking about tagging methods as questions. Or allowing the return value to "answer a question".
Actually this could expand to more that just boolean functions.
Every function that returns something is capable of being asked as a question.
What is the square root of n?
sqrt()...
Etc. Ponder the idea of generative question documentation.

- multiple names for levels of specificity
names can have different levels of specificity
short v
medium vec
descriptive: items
more descriptive purchasing_item_collection
the projectional editor provides a slider on how descriptive you want the code to look

- tag a function as exception smothering
sometimes we want a function to be constexpr and not crash if an exception is thrown.
We need a way to tag a function as catching any exception that is thrown internally.
This might mean that the return type is automatically an optional.. something to think about and make configurable

- auto dissolve / auto include comments
circle-jerking comment debate
code should be self-documenting and you don't need them
gray area on what people think is an appropriate amount of comments
no comments bad? too many comments bad?
we automate our stance in the gray area through unilang config.
I believe redundant comments are actually good despite self documenting code because
we want the pragmatics of one language (english) to match the perceived pragmatics of a programming language.
We should be able to derive that the meaning matches between the languages through something like function name and function statement +...
or possibly use other parts of the function and see if we get a 1 to 1 mapping to the comment, or a partial but complete mapping etc....
some linguistics discussion between english/programming languages and were they meet and what we should do about it

- swot analysis / SVOR analysis
we can add tokens for swot analysis.
yeah, i know swot analysis has always felt like a corporate joke,
but as part of our documentation initiative and as part of the pragmatic token set, it can help show why decisions were made.
Then if anyone cares, they can figure out if particular implementation or design was swotted. In which case, they can also see if any ideas were left out, etc.
easy to implement. essentially
[conceptual programming language concept] (may or may not be multi)
    [property about it that's under swot analysis] (multi)
        [strengths][weaknesses][opportunities][threats] (multis)  
per usual, we can generate any kind of artifacts out of this. most likely internal/external documentation.
possibly images if we want to pretend to be fancy.
There is something to say about whether things should be placed on the swot grid in correlation to importance or weight or something.
You know, like a political affiliation board kind of thing. I didn't hear anyone mention that I'd have to google to see if people actually do that.
I only mention it, because we may also want a unit for weight or importance, or percentage, or whatever to derive that.

- some kind of trait tagging for types
look at what is going on here:
https://github.com/I3ck/FlaggedT
templated tag types for other types to enforce consteaints.
Maybe we can have something like that to go alongside things in preconditions and postconditions.
It would seem to me that tagging the type would be more effective than a precondition or postconfdition, but I can see times when a pre/post condition are also the only option.

- debug tag on methods / data
for c and c++, you would wrap the code in debug flags, so that it is only compiled in debug mode.
I think what I'm getting at here is that you may want to tag a function as being a "debug function", then you use it in other code
the code generation ensures that the function is only actually called if the code was compiled in debug mode.  something like that.
We need to think about how release / debug mode might affect the language model of unilang


- Memory Model
Learn about memory models and incorporate them into UniLang
http://canonical.org/~kragen/memory-models/

- unitypes and multitypes
"Python, for example, is statically unityped and dynamically multityped; C is statically multityped and dynamically unityped; and Haskell is statically and dynamically multityped. Although it's a somewhat minor point, one can argue (with a little hand waving) that many assembly languages are both statically and dynamically unitype"
http://tratt.net/laurie/blog/entries/another_non_argument_in_type_systems.html
What is unilang, and how do we convert between type systems

- data / codata definitions
Work these definitions into UniLang:
So there are actually two kinds of data types: those which must be finite and those which can be infinite.
In computer science research, these often go by the shorter names:
"data", for the finite
"codata", for the infinite
http://www.tac-tics.net/blog/data-vs-codata

- be able to tag files as "interface glue"
this could be done on files but it might also want to be done on functions / data types / etc

- compare unilang gui to Stride

- generate as_ (copy) functions from public transformers
every transformer function can be turned into a copy returning alternative.
detect and generate these functions automatically.
Also, look at what the language Crystal does:
The standard convention is to use exclamation marks when a method will modify the object instead of returning a new one:

name = "Mr. Ferguson"
name.gsub "Mr.", "Dr."  #=> "Dr. Ferguson"

# The value of name is still "Mr. Ferguson"
name #=> "Mr. Ferguson"

# But if we use gsub! instead it gets changed
name.gsub! "Mr.", "Dr."  #=> "Dr. Ferguson"
name #=> "Dr. Ferguson"
There is a GUI code system called Stride. Lets compare it to UniLang and steal any of its good ideas.

here is an example, I've seen in real code:

///
/// Takes the given source string, and replaces all of the strings that match
/// the original with the replacement. This operation is done in place.
///
std::string &replace_strings(std::string &source, const std::string &original, const std::string &replacement);

///
/// Takes the given source string, and replaces all of the strings that match
/// the original with the replacement.
///
std::string replace_strings_copy(const std::string &source,
                                 const std::string &original,
                                 const std::string &replacement);
                                 

 - look for mismatch patterns
 create an algorithm to ask whether or not things like this are a mistake:
code code left code code right
code code left code code right
code code left code code right
code code left code code right
code code left code code right
code code left code code left
code code left code code right
code code left code code right
code code left code code right
code code left code code right

 - complexity classes
 all functions should be able to describe their complexity class
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
- semiotic breakdown (lack of binary signifies/signified combinations) 
if semiotics have taught me anything, its that I'm missing signifiers to particular signified objects.
In particular, multiple signifiers when combined equate to a single signified, (which in my language, and every other language) remains unamed. The point is, take either model of a sign (saussure to pierce), and make sure we can reprsent the language recursively in this way at the level of visible signs. and ensure they can be disjoint from other signs. This is an important realiszation, because I've already noticed myself doing this on multiple occasions. On the other hand, its essentially an argument against composition for everything being associated. (Don't worry, the transcompilation process will still use composition). But what I'm saying is, we express composition in the language not through composition itself, but through association.
We also allow for areas to bundle concepts/tokens/signs and give them their own name (signifier) to be used elsewhere.

so lets take a [mr][int][val].
This becomes its own language level concept that could be named (and in many times be implicitly named for you)

[changeable_val]
[mr][int][val]

/\ example not that important.

But now multiple functions can use [changeable_val] directly.

We've already done the same thing with dependencies (module/header/link/etc) onto types.

What does this mean for the language? It means the user (if they want to be more granular; and in customizable cases will be enforced to) specify closer to (signifiers)->signified where each signified is used as part of another level of a signifiers part to create another signified.

Ideally we want the (signifiers) to only be one name or one symbol, we may relax this on more discrete cases (such type annotations for parameter passing as talked about above)

Keep in mind, this is already a compositional association we did for sharing a data member between two structs, and how we build structs today. (more generally, I mean product/sum types) We give the data members their parent relations.
I think we will also be able to pull some ideas of "Semiotics of Programming" by Kumiko
















-generate idempotent assert in unit test
we might need to mark functions as idempotent.
actually, we want idempotent by default and possibly the need to specify situations that are not.
given this information we can then tell the test generator to create extra CHECK calls in the unit test to check the same result n number of times to check for idempotence
We need to get the arrange/act/assert portions as separate tokens first

-mark functions/errors as recoverable and non-recoverable


-Darwinian Data Structures (DDSs)
https://blog.acolyer.org/2018/12/14/darwinian-data-structure-selection/

-derived function call graph
based on inputs and outputs of function's arguments and return values,
we can use the types/identifiers to build a call graph.
This will help the user decide what functions to call.

-programs should have a list of keywords in which "people may use when talking about"
This is helpful for search engines
keywords sections on wikis
and alert keywords in slack

-be able to flag unit tests as "unsound", but still notify me.
sometimes you can predict unit tests failing in the future, and if they do, you want to be notified about it. However, if the unit tests fail, its not a blocking issue, and we don't want it to inconvenience anyone. We should be able to flag unit tests as either BLOCK_ON_FAIL, CONTINUE_ON_FAIL_BUT_NOTIFY ??
Of course, BLOCK_ON_FAIL should also notify someone.
We can also use the graph to derive unique function call scenarios

-[mr] mutable reference specifiers should be derivable
Like many developers, I've come to find the pain points for const qualifying.
If all of a sudden you realize you do need to make a change, then you need to change const all the way up the call stack. Same when dealing with references and copies. Someone at lunch told me thats why they don't even use const because its too much of a chore, and the protection it provides isn't really that big of a deal.
Also, const has no effect on the actual compiled code (the compiler strips them away)?

That opinion is a bit extreme, but I know how to get the best of both worlds.
You can leave out specifiers, and they will be derived based on how the function is used.
I think this is a better approach for quicker development time.
There may be some subtitles, but I'm sure I'll come across those during development.

I can see the need to basically have a unilang wrapper function over any kind of library or outside unilang
we opt for immutable reference by default (or immutable copy based on data type size/characteristics)?
Adjust based on what we discover through the call stack
uh oh! and what about moving? hmm?


-simple mutation tester 
We can eventually have this as part of the IDE, and slowly collect uncaught mutations.
For now, it can be as simple as raw file change with direct build/run test attempts

-ensure principals from "Large Scale C++ Advanced Levelization Techniques" are being done

-add the option to forward declare dependencies to speed up build times
The levelization techniques mentioned in 2016 CppCon mentioned using forward declares in the headers of files.
The advice was, never include a header file in another header file, unles you need the: enum, typedef, covariant return type, something else...
Otherwise, just forward declare. If you are only using the name in the function declaration as parameters and return types, there is no reason to actually include the header.
this is relevant for my employers monorepo now. So we will need a tool to auto-detect places to forward declare.










-struct usage warnings
parameter attribute: [must_use_all_members]
if you mark a struct parameter as [must_use_all_members] , then you should get a compiler warning,
if not all the members are used in the function that it is passed to. There might be some variations of the tag. For example, you may forward the struct param to another function, where the rest of the members are then used. You may accept that as meeting the requirements, and you may not. Requires some depth function searching across modules.

compiler suggestion: passing higher level struct than required
If you have a struct that's a.b.c.d, and you pass a into a function, and only use it like:
a.b.c.d, the compiler should warn you and say "hey, you are only using d,
why not perform a.b.c.d at the call site instead of everywhere inside the function.

compiler suggestion: suggest struct extrapolation from currently existing struct members.
for example:

struct settings{
 A a;
B b;
bool c_always_do_foo = true;
bool c_always_do_bar = false;
bool c_label = "sdsdf";  
}
compiler sees c_ and says: "maybe you should make a C_Settings"

compiler suggestion: suggest removing frivolous prefix/suffix identifier details.
example:

sruct Foo_Settings{
bool FooOn;
}
compiler can suggest removing "foo" as its deduced from the context of the name.
Something like that.

parameter attribute: [must_use_all_members_once]
warns if you use a particular data member 0 or >1 times






-allow a syntax for piping functions
many languages have this.
unix style.

1..100_000
  |> Enum.map(&(&1 * 3)) 
  |> Enum.filter(odd?) 
  |> Enum.sum
=> 7500000000






-analyze call chains to decide if the wrong function is being called
This would be able to detect copy and paste errors.
For example, let's say you have the following functions:

DoTask1();
DoTask1A();
DoTask2();
DoTask2A();

void DoTask1(){
   DoTask1A();
}
void DoTask2(){
  DoTask1A();
}
The static analyser should be able to determine that a possible mistake was performed in DoTask2.
It would need to be smart enough to conceptualize function grouping based on function names.
Also have a database of words that would normally be opposite. Copilot/Pilot for example.
If a bunch of copilot methods eventually call a pilot method, it could be a mistake.



-Allow an option to default initialize data members to something safe automatically.
If the user creates an empty constructor, we can check to see if they missed any, and attempt to provide a default initialization based on the type. If there is at least one data member that is dynamic, we will need a constructor no matter what, and could probably the generate constructor entirely. Then it will be closer to coding like in C++ where you don't have to specify functions.
Actually, we can probably go all the way. I'm changing this task to: generate constructors,copy constructors, and destructors if they don't exist, but should.
Copy and Destructor should be the easiest. Those are pretty mechanical.
Just some messiness with determining if the type is dynamic, and dealing with arrays, pointers, etc.

-output serialization format as an xml schema
should work with:
http://www.xml-tools.net/schemaviewer.html

-add why attribute when calling functions
https://www.youtube.com/watch?v=OrQ9swvm_VA
functions might automatically get a (char* why) argument.
But we don't actually have to change the code. It might just occur as comments in the code



-tag functions as being able to be called n times sparking code generation
string may have a function append_char(char)
we may also want append_char_n_times(char,size_t)
If we tag the function as being something that can be repeatably called, we can invoke code generation to get the n times functions. It's also something we can say in documentation.
"This function is allowed to be called multiple times in a loop".
need to do more research on the matter. get some terminology right.
We basically want a language for describing a method's affect on state over time.
A "diluting function" for example always puts the object into the same state.
I made up that term but I'm sure there is a language to describe these kinds of things. maybe need to look into category theory

-state and verify how much memory is allocated in a test
this will help avoid problems where more memory is being allocated than intended, etc.

-allow restricted pointers
There are a lot of edge cases I'm not confident about.
We start with function scope only as in restricted parameters.

Let me post some questions that I need to get answered:
is it ok to use ristrict when the types aren't even the same?
Is it ok to use restrict when there is only one parameter?
Is there a way to catch the UB when a user violation restrict keyword?

From UniLang's perspective we may want different terminology considering Unilang abstracts pointers away in the form of references. Independent? Unique? only access point?
I'd like to think about this some more.

-every tool or function should answer a question
we should be able to define regex-like questions for every function and program to help aid in documentation and automatically answering questions from people
but also, every question needs to be backed by a unit test so we can ensure that the answer is still correct

-add not_null static asserts for c functions that use references
Lots of customziation on how we want this to look. Probably guarded by a custom macro since our build is broken in debug mode anyways. Can probably just use normal cassert under the custom macro wrapper.

-unit dimensionality
// e.g., 1 -> " m"
//       0 -> ""
//       2 -> " m^2"
//      -3 -> " m^(-3)"

-oracle and metamorphic testing specified
I'd like to make sure these kinds of manual tests and property based tests are mentioned inside unilang. I'm not sure how much it will span (into code generation?)

-ensure unit tests meet performance requirements as part of the test

-bubble for data member composition
https://beta.observablehq.com/@mbostock/d3-zoomable-circle-packing

-integrate modules into build
starting using c++ modules in bazel
see if hcp needs adjusted for this
see if unilang needs adjusted for this
http://mbostock.github.io/d3/talk/20111116/pack-hierarchy.html

-function explosion via enum parameter
lets say a function takes a 3 value enum like:
func(e);
be able to tag the enum parameter so that we get function generation of additional funcs:
funcValueA(), funcValueB(), funcValueC(), which will just call func forwarding the implicit argument.

-create compilation databases for better clang analysis
https://github.com/rizsotto/Bear

-C++ meta classes
Support Herb Shutter’s C++ meta classes proposal

-steal any good ideas from cucumber for testing

-avoid side channel attacks in generated code
super minor, but nice to recognize that we can add these tags, or use libraries.. or wipe memory whatever to avoid these kinds of attacks where specified

-pairwise testing support

-sankey diagram for functional decomposition
https://nivo.rocks/sankey/
http://mbostock.github.io/d3/talk/20111018/partition.html
https://beta.observablehq.com/@mbostock/d3-sankey-diagram

-difficulty naming particular concepts (definitions, terminology)
Here is a list of particular concepts I've come across while implementing unilang that I had a hard time naming. As they say, "one of the hardest parts of computer programming is naming."
I'll leave this as an issue where I collect these weird concepts. And we can close the issue when we have some kind of document or artifact for these things. I half-started something in the task_executer.hcp, which obviously needs to be moved to an actual document somewhere.
I'm kind of against documentation that isn't also code, so we might just create data types for these things that aren't actually used in software.. yet!.

example

struct {
std::string name;
std::string definition;
//etc...
}
what do we call a "fundamental type or an ADT"?
-> data type type?
-> data_abstraction_type = abstracted/non-abstracted?
what do we call a "method that is either part of the interface or part of the implementation"?
-> module_method_visibility? = interface/definition
In computer science (and oddly enough, in actual programming as well), things always come in pairs. Every read has its write. Every setup has its cleanup. Every open paren has a close.

In this spirit, every type in functional programming comes equipped with an introduction rule and an eliminator. The introduction rule makes objects of that type. The eliminator allows you to use objects of that type.
Of course, as usual, "introduction rule" and "elimination rule" are the fancy-ass type theory names. In functional programming languages, we call introduction rules "constructors" and the eliminator rules... also "constructors". I'll explain.
(from: http://www.tac-tics.net/blog/data-vs-codata)



-warning about naming methodology for functions 
fetch - going to take some time
get - constant time
calculate - does some arithemtic to produce value
find - if it traverses and looks based on some predicate

words to avoid (do,handle,perform,return,compute);

avoid using class name in non-manager class methods
message.save() NOT message.saveMessage()

don't use param names in function name
findUser($userId, $token) NOT findUserByUserIdAndToken($userId, $token)

method called Print() (are you sure you don't want to overload << instead)

int64_t account
"what do you mean account? AccountId perhaps?"

Function names should be verb-followed-by-subject

Functions like:
Handle_X
On_X (OnEvent / OnClick / etc)

Are Homonyms and synonyms both bad for identifiers/function names?
Might cause confusion or uncertainty
The mixture of synonyms and homonyms, which is commonly found in source codes, maximizes confusion and aggravates comprehension efforts enormously.

A naming relation R is consistent if and only if the mapping is bijective, i.e. each identifier name from N is paired with only one concept from C and each concept from C is paired with only one identifier name from N.

http://michalplachta.com/2017/01/22/folklore-and-science-of-naming-practices/
has other good information too

IMAGE:
Identifier Names / Concepts
book               to book / a book
accountNumber      an account number
number             an account number / a phone number

TABLE:
Naming advice from “Clean code”4    Rule from “Concise and Consistent Naming”3
use intention-revealing names   choose correct names
avoid disinformation    choose correct names
make meaningful distinctions    choose consistent names
use pronounceable names choose correct names
use searchable names    choose correct names
avoid encodings choose consistent names
avoid mental mapping    choose consistent names
don’t be cute   choose consistent names
pick one word per concept   choose consistent names
don’t pun   choose consistent names
use solution domain names   choose concise names
use problem domain names    choose concise names
add meaningful context  choose concise names
don’t add gratuitous context    choose concise names


-integrate static analysis tools (if these are alive)
http://btorpey.github.io/pages/REAME.md/index.html
https://github.com/Ericsson/CodeChecker
code maat
code scene
evolution radar
moose platform



-how do we implement function overloads for decomposed objects? and should we?
Take the following example:

struct Object{
foo a;
foo b;
};
Different implementations:

void overload(foo a, foo b)
{
   //actual implementation uses foo
}

void overload(Object o)
{
    //forward
    return default_plot_titles(o.a,o.b);
}
or

void overload(foo a, foo b)
{
   //forward
   overload(Object{a,b});
}

void overload(Object o)
{
   //actual implementation uses object.foo
}
Assuming this is a good idea to produce both, which ones do we choose?
What is valid for an interface to the user? both? Should this be done automatically?
(that would get out of hand very fast because as state bubbles to the top, all function interfaces would grow according to composition size of the types they take in...)
Hmm, it would be cool to have just for the sake of looking productive. Maybe we need some kind of cut off point, because a goal of good code would be not to have too many parameters. So we'd only go as far as that limit. Although, now that I've said that I guess it would be best to only take in only the objects and avoid the multi-parmaeter ones. Hmm.. but that makes the implementation a little bit more verbose... and by that logic, every function should only take 1 parameter. Hmm, things to think about.




-is a count a unit of measurement
philosophical question to improve static analysis.
is count a unit of measurement? Can we look at any number and warn about missing units of measurement? And ensure everything has a unit, where the vast majority of identifiers that dont have a measurement become a count measurement?

might not be needed since we already want to analyze the identifier name and deduce based on that if it lends itself to a measurement


-anytime a file is deleted, check to see if it is referenced anywhere in code
^ as part of static analysis for like code review



-how do we group functions? by structure/name similarity, or by the types they operate under?
Here is a prime example:

///
/// \addtogroup plot_style utilities
/// @{
///
/// @brief      Gets the plot styles according to a style selection
///
/// @param[in]  selection The category of plot styles to get
///
/// @return     A list of different plot styles to use for varying image generation
///
std::vector<plot_style> get_plot_styles(style_selection selection);

///
/// @brief      We need to convert the C++ enumerated type into a string that R understands
/// R customizes the plot style using a string representation.  This can also be called by the user
/// In order to get that abbreviation for use on file names.
///
/// @param[in]  style  The plot style to convert into an abbreviated R string
///
/// @return     An abbreviated string representation of the plot style
///
std::string to_r_param(plot_style style);
///
/// @}
///


///
/// \addtogroup bar_placement utilities
/// @{
///
/// @brief      Gets the bar placement styles according to a style selection
///
/// @param[in]  selection The category of bar placement styles to get
///
/// @return     A list of different bar placement styles to use for varying image generation
///
std::vector<bar_placement> get_bar_placement_styles(style_selection selection);

///
/// @brief      We need to convert the C++ enumerated type into a string that R understands
/// R expects the bar placement as a boolean which we send over the cli as a string.
/// This can also be called by the user In order to get that abbreviation for use on file names.
///
/// @param[in]  style  The bar placement style to convert into an abbreviated R string
///
/// @return     An abbreviated string representation of the bar placement style
///
std::string to_r_param(bar_placement style);
///
/// @}
///


///
/// \addtogroup graph_orientation utilities
/// @{
///
/// @brief      Gets the graph orientation styles according to a style selection
///
/// @param[in]  selection The category of graph orientation styles to get
///
/// @return     A list of different graph orientation styles to use for varying image generation
///
std::vector<graph_orientation> get_graph_orientation_styles(style_selection selection);


///
/// @brief      We need to convert the C++ enumerated type into a string that R understands
/// R expects the graph orientation as a boolean which we send over the cli as a string.
/// This can also be called by the user In order to get that abbreviation for use on file names.
///
/// @param[in]  style  The graph orientation style to convert into an abbreviated R string
///
/// @return     An abbreviated string representation of the graph orientation style
///
std::string to_r_param(graph_orientation style);
///
/// @}
///
Should I actually group all of the get_x_styles together?
and group all of the to_r_param functions together?
Whose to say. What choice has evidential proof of being better for future maintenance?

-Flesch–Kincaid readability tests
add these as apart of lint process




-detect URLs in the values of any tokens and check their availability
optional static analysis:
does string have url in it?
extract url
test it for 200 response
report issues




-different types of invariants (hillelwayne.com)
state="at least 1 server is online"
action="we do not remove servers if below capacity"
behavior="eventually we have enough servers"



-question/answer tokens for language concepts 
functions and classes solve problems. We want to aid in code re-use. Add tokens to allow question/answer content so searching can be done easier. And slack bots can respond with possibilities.
Basically,
Q: how do I traverse a filesystem?
A: use /sdf/dfgd/sdf/tree_walker.hh

-duplicate coder identifier
tools that currently work, but need integrated:
fdupes

-flag optional statements in function to generate dispathcing functions automatically

basically:
void do_thing(Thing){
  [optional]validate(thing)
}


turns into:
enum validate{
 yes,
 no
}

void do_thing(Thing, validate){
  possibly_validate(thing,validate)
}

possibly_validate(thing,validate){
   switch(validate){
   case: validate::yes: perform_validate_step(thing);
   case: validate::no: perform_skipped_validation_step(thing);
}

void perform_validate_step(thing)
{
}

void  perform_skipped_validation_step(thing)
{
}





-preconditions and postconditions as part of arguments
we can keep the root assertions as well, but we should also add tokens so that individual arguments can be tagged with conditions as well



-check for getters and setters that could provide uniformity
struct Foo{
    struct Bar{
        int x;
    }
}
and

struct Baz{
        int x;
}
should both provide a get/set x function to support uniformity across templates


-label branches to help the branch predictor and the reader of the code
We might have branches in our code, but there is an expected execution order.
We can annotate this to allow the program to possibly run faster and give an indication to the reader on what branch will likely be hit on normal program executions.

Could this labeling eventually be done automatically? ye, probably, but we should still have it as a token? I think so.


-linear/row types
"I did my Bachelor's thesis on adding (linear) phantom (row) types to C
There's so much potential there it's ridiculous. The semantics of Cyclone/Rust-style ownership and borrowing took about 5 lines to describe to get the complete system 'for free', iirc. It's the same with typestate."
What are linear / row types? How can we account for them in Unilang

-every func taskes 1 parameter. self reducing types
if every func takes 1 parameter, we will sometimes have higher composedtypes,
and want to pass in the composed types inside. We should be able to automatically convert types
to another type automatically. We generate the implicit conversions automatically So then we can parameter pass the same as type, but get a smaller type at the function definition level and in the body.
This will make diffs really small. And refactoring easier.

-type assumptions should create splits in function implementation, when data is adjusted
lets say a function takes an integer, and that integer cannot be negative,
but we allow negative to be passed in...
do we make the adjustment inside / outside the function implementation
(there are some other things to consider here... with pre.post conditions)...
we will ensure that three functions get created

1. a function that has assumptions but does not spend computation time checking
2. a function that has assumptions but allows anything, and performs the adjustment
3. a function that performs the value adjustment
(possibly another generated function and enum, that does the dispatch)


-Cache the Loop End Value
for (size_t i = 0, len = strlen(s); i < len; ++i)
 if (s[i] == ' ')
 s[i] = '*'; 
ill be interested to see if this really speeds up impls

-detect certain things in code, and create a documentation link to a webpage showing examples
we might be able to do this at a function level, lol.
Take the documentation, and unit tests and transform them into some kind of tutorial/examples page, and link to that on the function. Or just detect words/concepts or something and have links to pages on those.
like anytime a particular object is used, we can link to a wiki about using the class.
more noise lol

-custom keyboard
should we make a keyboard for special unicode tokens as keys? hot keys etc

-expected container size
very often containers are passed around functions and people often wonder how much data is in them.
It would be nice if the author could leave a remark like:
"This container is expected to have 10 - 20 items in it because thats the number of configs we have.
The size of the container is likely to scale with the number of configs we have yada yada. "
or
"This container is expected to contain thousands of segments depending on the length of the course.
Its probably something like 800 segments for every mile"

These things could be expressed with a number range, and an explanation token


-static analysis of mis-ordered parameters through identifier matching.
example of param flip issue:
```
void func (int a, int b);  

void some_func(){
   int a; int b;
   func(b,a); //static analysis says this is a mistake
}
```



-Allow transformation functions to also return copies via a wrapper
In the Jstd, I would always write:
```
void Lowercase(Str & s);
Str As_Lowercased(Str s);
```
If we always create the transformer first, we can get the As_ functio for free.
From Sean Parent's talk:
The Permutation Paradox:
"There is a duality between transformations and the corresponding actions:
An action is definable in terms of a transformation and vice versa:
void a(T& x){ x = f(x); } // action from transformation
and 
T f(T x){a(x); return x; } // transformation from action

Actually they are both turring complete, so either one can be used to create the other.
There will be some natural language processing for the new function names of course.

"Despite duality, independent implementations are sometimes more efficient, in which case both actions and transformations need to be provided." - Elements of Programming (section 2.5)



-Language specifiers for describing how the code achieves adopting the technology
GOTO video: How to Break the Rules by Dan North
talks about this book: The Goal: A Process of Ongoing Improvement
And its really important to break down "How to adopt a technology"

So here are the things we want to specify on the software we create, and they should be tokens in the language:

What is the power of the technology?
What limitation does the technology diminish?
What rules enabled us to manage this limitation?
What new rules will we need?
by the way, 3 should not be !(4)

-suggest enums in place of boolean parameters



-generate free function that iterates over all combinations of iterable data members
example:
something like this:

```
struct styles{
vector<color> colors;
vector<sizes> sizes;
}
```
should generate a function that does this:
```
template <Fun>
void for_each_variation(styles v, Fun fun){
    for (auto color: v.colors){
        for(auto size: v.sizes){
            fun(color,size);
        }
    }
}
```


-high level data flow animator through function call stack
see what kind of visualizations are out there to do this.
It could be big an complicated showing a dictionary of custom types being manipulated though a function.
It could also be simple something like showing the type transitions between function calls.
Hmmm.. we would have to know that two types are related via a transformation. But I suppose this could be done by tracing parameters / return values. And seeing what goes in, and what comes out.


-allow syntax for wrapping a function
to avoid incorrect return types like this:
unsigned int size(){
return foo_set.size();
}
should have been a size_t, and a little redundant to type and document.
documentation can be generated automatically if we know that its wrapping the function.
Also, we would be able to automatically forward arguments, and automatically return from the call if we know that is wrapping





-specify functions as inverses creating automatic tests
you should be able to label functions as inverses. this will automatically generate tests
```
T before;
before == serialize(deserialize(...)))
```

-check for unfinished sentence in comment
sometimes you are writing code, get distracted, and you don't finish writing a comment.
instead of having people catch this in review, lets try to have the compiler catch it for you.



-rules on enforcing parameter order
in what order should parameters be passed?
There may be a lot of opinions about this, but at the very least we can codify rules and enforce them.

I've noticed personally,

we at least want consistency. If something is passed first most of the time, we should make sure it keeps getting passed first. And maybe the higher up the call chain that the object existed, the more priority it should get to being placed first in the paramter list.

Another opnion maybe to pass the bigest objects first. Again, that just something that people may do conceptually to better understand what is being moved around. Usually because that reserves booleans and enums and flag like types to be ordered last. Again, these are just opnions.

Lastly, we may want to pass things that are being transformed first, followed by things that are being copied(but mutable), followed by things that are read only.

Also, if it is a tie, we might want to trump by whether it is a container or by the sizeof the object

